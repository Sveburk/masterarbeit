\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usetikzlibrary{positioning, arrows.meta}
\usepackage{pifont}  % Für die Kästchen und Häkchen-Symbole
\usepackage{minted}  % Für Python-Code
\usepackage{xcolor}  % Zum Definieren und Verwenden von Farben
\definecolor{LightGray}{gray}{0.9}
\definecolor{abbrev}{RGB}{255,153,153}      % Rot
\definecolor{add}{RGB}{204,255,238}         % Hellgrün/Türkis
\definecolor{sic}{RGB}{255,255,153}         % Hellgelb
\definecolor{unclear}{RGB}{255,230,184}     % Hellorange
\definecolor{date}{RGB}{153,153,255}        % Blau
\definecolor{organization}{RGB}{255,153,255}% Pink
\definecolor{place}{RGB}{204,153,255}       % Lila
\definecolor{person}{RGB}{153,255,153}      % Hellgrün
\definecolor{signature}{RGB}{153,255,153}   % Hellgrün (gleiche Farbe wie Person)

\usepackage[hidelinks]{hyperref} % Für die Hyperlinks im Inhaltsverzeichnis
\usepackage[a4paper, left=2.5cm, right=2.5cm, top=2cm, bottom=2cm]{geometry}

\title{\Huge Masterarbeit Tagebuch}
\author{Sven Burkhardt}
\date{}

\begin{document}
\maketitle
\noindent
\hrulefill

\newpage % Neue Seite für das Inhaltsverzeichnis
\tableofcontents

%dieses Dokument wird blogartig geführt. Neuste Einträge sind oben einzufügen. 

%___________________________________________________________________________
\noindent\hrulefill
\section{Systemübersicht Virtuelle Maschine \small 07.05.2025}

Für die Darstellung und Endnutzung der für die Masterarbeit gewonnen Daten ist von Sorin und mir in einem Feedbackgespräch die Idee entstanden, eine Virtuelle Maschine der IT-Services der Uni Basel zu nitzen. dafür wurde Lukas  am 07.10 per Mail angefragt. Ziel ist ein Userinterface zu baeuen, indem per Suchmaske die JSON Dateien durchsucht werden können, per IIIF-Server auf die Bilddateien der Akten zuzugreifen, und in einem weiteren Schritt ggf auch auf meine Nodegoat-Datenbank zuzugreifen.

\begin{center}
\begin{tikzpicture}[
    box/.style={rectangle, draw, minimum width=12cm, minimum height=4.5cm, align=center},
    innerbox/.style={rectangle, draw, fill=gray!10, minimum width=5cm, align=left},
    small/.style={font=\small},
    arrow/.style={-{Latex[length=3mm]}, thick}
]

% Oberer Text über dem Hauptrechteck
\node[small] at (0,3) {\texttt{maennerchor\_murg.philhist@unibas.ch}};

% Hauptrechteck
\node[box] (mainbox) at (0,0) {};

% Text im Hauptrechteck: oben links
\node[innerbox, anchor=north west, align=center] at ([xshift=0.3cm,yshift=-0.3cm]mainbox.north west) {
    \textbf{Virtuelle Maschine}\\
    mongod\\
    DB (json)
};

% Text im Hauptrechteck: rechts oben
\node[innerbox, anchor=north east, align=center] at ([xshift=-0.3cm,yshift=-0.3cm]mainbox.north east) {
    \textbf{cantaloupe}\\
    IIIF\\
    für Bilder
};



% Text im Zentrum des Rechtecks
\node[innerbox, anchor=south, align=center] at ([yshift=0.3cm]mainbox.south) {
    \textbf{mdr-core}\\
    \texttt{DJANGO}
};


% Pfeil aus dem Hauptrechteck nach unten
\draw[arrow] (mainbox.south) -- ++(0,-2) node[below] {Userinterface};

\end{tikzpicture}
\end{center}


\subsection{Fehleranalyse und Verbesserungsvorschläge der JSON-Extraktion}

Im aktuellen Stand der automatisierten Extraktion historischer Metadaten aus Transkribus-XML-Dokumenten zeigt sich, dass einige der generierten JSON-Dateien inhaltlich nur teilweise oder gar nicht gefüllt sind. Die Debug-Ausgaben des Skripts deuten auf folgende Hauptprobleme hin:

\begin{itemize}
    \item \textbf{Leere JSON-Dateien:} In mehreren Fällen (z.\,B. bei \texttt{Akte\_696}) wurden keinerlei Entitäten erkannt. Dies betrifft insbesondere Dokumente mit wenigen klaren semantischen Ankern oder fehlerhafter OCR-Struktur.
    \item \textbf{Rollen werden häufig nicht erkannt:} Obwohl die Normalisierung deklinierter Rollen (z.\,B. \textit{Ehrenvorsitzenden} → \textit{Ehrenvorsitzender}) implementiert wurde, erscheinen viele Rollen nicht im JSON. Vermutlich erfolgt keine korrekte Zuordnung zum Rollenschema.
    \item \textbf{Einzelne Namen wie ``Herrn'' oder ``Ortsverbandsleiter'' werden fälschlich als Person erkannt:} Die Blacklist filtert einige dieser Fälle, jedoch nicht konsistent oder umfassend genug.
    \item \textbf{Falsch-positive Personen:} In Kontexten wie ``Dirigenten'' oder ``mich'' werden Begriffe extrahiert, die keine validen Personennamen sind.
    \item \textbf{Mehrdeutigkeiten bei zusammengesetzten Ausdrücken:} Konstruktionen wie ``Vereinsführer des Männerchor'' führen zur fehlerhaften Aufspaltung zwischen Personen- und Organisationsentitäten.
\end{itemize}

\subsection{Vorgeschlagene Verbesserungen}

\begin{itemize}
    \item \textbf{Erweiterung der Rollenextraktion:} Rollen sollten auch erkannt werden, wenn sie in Verbindung mit Personennamen stehen (z.\,B. ``Ehrenvorsitzenden Burger''). Eine robustere Normalisierung mit Regex-Support für maskuline/feminine Deklinationen ist bereits in Arbeit.
    \item \textbf{Blacklist für generische Begriffe erweitern:} Begriffe wie ``mich'', ``Herrn'', ``Ortsverbandsleiter'' sollen systematisch ausgeschlossen oder nur in Kombination mit validen Namen akzeptiert werden.
    \item \textbf{Verbesserung des Kontextverständnisses bei Personenextraktion:} Eine Gewichtung nach Position im Satz (z.\,B. Grußformeln) oder in Verbindung mit Rollenwörtern könnte helfen, valide Personen zu priorisieren.
    \item \textbf{Evaluation der OCR-Qualität pro Datei:} Ein hoher Anteil fehlerhafter Tokens könnte vorab mit einem Heuristikwert ermittelt und markiert werden.
    \item \textbf{Fallback-Strategien für autor/recipient:} Falls kein \texttt{author} oder \texttt{recipient} erkannt wird, aber Custom-Tags mit solchen Informationen vorhanden sind, soll ein LLM-gestützter Vorschlag übernommen werden.
\end{itemize}

Die nächsten Schritte umfassen gezielte Tests mit exemplarischen Dokumenten, um die Wirkung der geplanten Anpassungen zu evaluieren. Besonders relevant ist dabei die korrekte Auflösung von Rollenzuweisungen und die zuverlässige Filterung nicht-personaler Begriffe.


\section{Änderungen im assigned\_roles\_module und person\_matcher\small 06.05.2025}

\subsection*{Kernaussagen der Änderungen}
Die letzten Änderungen konzentrieren sich auf die Verbesserung der Entitäten-Erkennung und das Matching von Personen, Orten und Rollen. Es wurden gezielte Verbesserungen und Anpassungen in den folgenden Bereichen vorgenommen:\\

\begin{itemize}
    \item Orte werden nun wieder korrekt mit der Nodegoat-ID gematcht. Dies stellt sicher, dass die geografischen Entitäten präzise zugeordnet und identifiziert werden.
    \item Das \texttt{assigned\_roles\_module}-Script wurde optimiert, um den Genus der erkannten Rollen zu normalisieren und diese im Nominativ Singular darzustellen.
    \item Es muss jedoch noch weiter optimiert werden, um sicherzustellen, dass auch Einzelrollen wie "Der Vereinsführer" korrekt als erwähnte Personen erkannt werden.
    \item Der \texttt{person\_matcher} kann nun auch Personen matchen, wenn nur ein Vor- oder Nachname vorhanden ist. Dies erweitert die Flexibilität des Matchings erheblich und verbessert die Erkennungsrate bei unvollständigen Namen.
    \item Die Deduplizierung von Personen funktioniert weiterhin wie erwartet. Das System sorgt für eine effiziente Zusammenführung ähnlicher Entitäten, ohne Duplikate zu erzeugen.
\end{itemize}

\subsection*{Nächste Schritte}
\ding{113} Weiterführung der Optimierungen im Bereich der Rollenerkennung und der Personenzuordnung\\
\ding{113} Verbesserung der Fehlerbehandlung bei besonderen Rollenkombinationen\\
\ding{113} Automatisierte Tests für die neuen Matching-Strategien einführen\\

\subsection*{Strategie zur Verbesserung des Rollen-Matchings per ChatGPT}

Idee: überarbeiteter Workflow, der die beiden Module \texttt{assigned\_roles\_module} und \texttt{person\_matcher} systematisch einbindet. Ziel ist die zuverlässige Erkennung von Rollenangaben wie \textit{»Ehrenvorsitzender Burger«} und deren saubere Trennung in Rolle und Person sowie die Ergänzung bereits erkannter Personen um zusätzliche Rollen.

\begin{itemize}
    \item \textbf{Früherkennung von Rollen in Personenangaben:} \\ Bereits beim Parsen der \texttt{custom\_data["persons"]} wird jeder \texttt{raw\_token} auf Rollen untersucht. Dazu wird \texttt{extract\_role\_in\_name(token)} aufgerufen, um Kombinationen wie \textit{»Ehrenvorsitzender Burger«} zuverlässig aufzuteilen.

    \item \textbf{Rollenerkennung im Fließtext:} \\Zusätzlich wird \texttt{extract\_standalone\_roles(text)} auf das Transkript angewendet, um unabhängig von XML-Metadaten Rollen wie \textit{»Der Vereinsführer«} zu identifizieren.

    \item \textbf{Normalisierung und Abgleich:} \\Die erkannten Rollen werden mit \texttt{normalize\_role\_name()} in ihre Grundform gebracht (z.\,B.\ „Ehrenvorsitzenden“ $\rightarrow$ „Ehrenvorsitzender“). Die zugehörigen Namen werden mit \texttt{normalize\_name()} in Vor- und Nachname getrennt und mit \texttt{match\_person()} gegen bekannte Personen abgeglichen.

    \item \textbf{Erweiterung vorhandener Personen:} \\Stimmen Namen oder IDs mit bereits erkannten Personen überein, wird die Rolle hinzugefügt, ohne ein Duplikat zu erzeugen. Der Abgleich erfolgt über \texttt{normalize\_name\_string()} und \texttt{deduplicate\_persons()}.

    \item \textbf{Bewertung der Übereinstimmung:} \\Bei eindeutigem Match wird \texttt{match\_score = 100} und \texttt{confidence = "llm-matched"} gesetzt. Bei unklarem Abgleich kann \texttt{confidence = "partial"} verwendet werden, um die Herkunft der Information nachvollziehbar zu machen.

    \item \textbf{Zusammenführung aller Kandidaten:} \\Die Ergebnisse aus XML, Fließtext und Rolle-im-Namen-Kombinationen werden zu einer finalen Personenliste kombiniert, die dedupliziert und mit Rollen angereichert als \texttt{mentioned\_persons} im JSON-Dokument gespeichert wird.
\end{itemize}

\noindent\hrulefill

\section{Verbesserte Deduplizierung in Person- und Orts-Matchern \small 30.04.2025}
\small\textit{Optimierung der Deduplizierungslogik für Personen und Orte in den JSON-Ausgabedateien}\\

\subsection*{Kurzbeschreibung}
Die Module zur Deduplizierung von Personen und Orten in den JSON-Ausgabedateien wurden grundlegend überarbeitet. Die neue Implementierung verhindert, dass Entitäten mehrfach in der Ausgabe erscheinen, und priorisiert dabei Einträge mit vorhandener Nodegoat-ID. Zudem werden alternative Namensformen zusammengeführt, um ein umfassenderes Verständnis der identifizierten Entitäten zu ermöglichen.

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Überarbeitung des person\_matcher.py Moduls}
\ding{51} Gruppierung von Personen nach nodegoat\_id oder normalisiertem Namen implementiert\\
\ding{51} Priorisierung von Einträgen mit Nodegoat-ID bei der Deduplizierung\\
\ding{51} Kombination und Konsolidierung von Rolleninformationen aus mehreren Nennungen\\
\ding{51} Optimiertes Scoring-System für die Auswahl der besten Einträge

\subsubsection*{\small Optimierung des place\_matcher.py Moduls}
\ding{51} Neuimplementierung der deduplicate\_places-Methode mit verbesserter Gruppierungslogik\\
\ding{51} Zusammenführung alternativer Ortsnamen in einem deduplizierten Eintrag\\
\ding{51} Priorisierung von Ortseinträgen nach Vorhandensein und Qualität von IDs\\
\ding{51} Deduplizierung basierend auf normalisiertem Ortsnamen für Einträge ohne ID

\subsubsection*{\small Integration im Hauptskript}
\ding{51} Anpassung der Verarbeitung in transkribus\_to\_base.py für deduplizierte Personen\\
\ding{51} Beseitigung von Doppeleinträgen durch vereinheitlichte Deduplizierung\\
\ding{51} Konsistente Verwendung der verbesserten Matcher-Module\\
\ding{51} Erhalt und Zusammenführung aller relevanten Informationen in deduplizierten Entitäten

\subsection*{Nächste Schritte}
\ding{113} Quantitative Evaluierung der Deduplizierungsqualität auf dem Gesamtdatensatz\\
\ding{113} Dashboard zur Visualisierung der Entitätsbeziehungen entwickeln\\
\ding{113} Integration mit Batch-Prozessierung für alle Dokumente\\
\ding{113} Automatisierte Tests für die Matching-Qualität implementieren

\subsection*{Offene Fragen}
\ding{113} Wie kann die Konsolidierung von semantisch identischen Rollen verbessert werden?\\
\ding{113} Könnte eine Clustering-Methode zur Identifikation weiterer Duplikate beitragen?\\
\ding{113} Wie sollen Grenzfälle mit sehr ähnlichen, aber nicht identischen Entitäten behandelt werden?\\

\section{Vereinheitlichung der Schnittstellen und Dataframes \small 14.04.2025}
\small\textit{Integration der Datenvalidierung mit CSV-Export und Optimierung der Ortsanreicherung}\\

\subsection*{Kurzbeschreibung}
Heute die Module zur Datenverarbeitung erweitert mit einem vereinheitlichten Interface für Validierungsergebnisse. Die CSV-Export-Funktionalität wurde implementiert und die Ortsabgleichslogik deutlich optimiert. Zusätzlich wurden Dataframe-Manipulationen für strukturierte Analysedaten verbessert.

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Validierung und CSV-Export}
\ding{51} CSV-Exportformat für Validierungsfehler implementiert\\
\ding{51} Strukturierte Sammlung von Fehlertypen nach Dokumenten und Kategorien\\
\ding{51} Aggregierte Statistiken zur Datenqualität hinzugefügt\\
\ding{51} Pandas-Dataframes für konsistente Datenanalyse integriert

\subsubsection*{\small Optimierung des Ortsabgleichs}
\ding{51} ID-Generierung für neue Ortsentitäten systematisiert\\
\ding{51} Fuzzy-Matching durch exakte Vorfilterung beschleunigt\\
\ding{51} Kaskadierendes Matching (erst exakt, dann Teilstring, dann Fuzzy)\\
\ding{51} Priorisierung von IDs nach Qualität (Nodegoat > Geonames > Wikidata)

\subsubsection*{\small Schnittstellen-Vereinheitlichung}
\ding{51} Konsistente Parameter und Rückgabewerte zwischen Modulen\\
\ding{51} Verbesserte Fehlerbehandlung mit spezifischen Exceptions\\
\ding{51} Logging-Framework für detaillierte Diagnose eingerichtet\\
\ding{51} Type-Annotations für bessere Code-Dokumentation hinzugefügt

\subsection*{Nächste Schritte}
\ding{113} Dashboard zur Visualisierung von Entitätsbeziehungen entwickeln\\
\ding{113} Automatisierte Tests für die Matching-Qualität erstellen\\
\ding{113} Batch-Prozessierung für große Dokumentmengen optimieren

\subsection*{Offene Fragen}
\ding{113} Wie können wir die Matching-Parameter automatisch optimieren?\\
\ding{113} Wann erhalten wir die vollständigen Nodegoat-IDs für alle Entitäten?\\

\noindent\hrulefill

\section{Validierung und Orts-Matching \small 13.04.2025}
\small\textit{Erweiterung der Datenvalidierung und Fehlerausgabe im Transkriptions-Workflow}\\

\subsection*{Kurzbeschreibung}

Erweiterung des Validierungsmoduls für strukturierte Prüfung exportierter JSON-Dokumente. Verbesserung des Ortsabgleichs mit Groundtruth-Tabelle zur eindeutigen Zuordnung von Geonames- und Nodegoat-IDs.

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Validierungsmodul (\texttt{validation\_module.py})}
\ding{51} Erweiterte Validierungslogik \texttt{validate\_extended()} implementiert\\
\ding{51} Prüfung auf Pflichtfelder: \texttt{recipient}, \texttt{creation\_date}, \texttt{creation\_place}\\
\ding{51} Prüfung von \texttt{mentioned\_places} auf Geonames- und Nodegoat-ID\\
\ding{51} Ausgabe einer statistischen Fehlerübersicht (z.B. „Geonames-ID fehlt: 5×“)

\subsubsection*{\small Transkribus-Hauptskript}
\ding{51} Einbindung des erweiterten Validierungsmoduls\\
\ding{51} Speichern von Fehlern pro Datei in strukturierter Liste\\
\ding{51} Ausgabe der häufigsten Fehlerarten am Ende der Verarbeitung\\
\ding{51} Fix für \texttt{UnboundLocalError} bei fehlgeschlagenem Dokumentexport

\subsubsection*{\small Ortsabgleich (Place-Matching)- Funktioniert noch nicht}
\ding{51} Lowercase + Strip für Eingabe und Vergleichswerte vereinheitlicht\\
\ding{51} Threshold bei Fuzzy-Matching auf 75 gesetzt\\
\ding{51} Fehlerbehandlung bei fehlenden oder ungültigen Wikidata-IDs (z.B. float statt string)\\
\ding{51} Entfernung des Feldes \texttt{type} aus allen Place-Objekten und JSON-Exports\\
\ding{51} Debug-Ausgabe zur Match-Qualität hinzugefügt

\subsection*{Nächste Schritte}
\ding{113} Validierungsfehler zusätzlich in CSV speichern\\
\ding{113} Orte ohne IDs visuell markieren oder zur Nachprüfung kennzeichnen\\
\ding{113} Schutzmechanismus gegen ID-Veränderung im LLM-Enrichment einbauen

\subsection*{Offene Fragen}
\ding{113} Wie bekomme ich die Groundtruth-Daten?
\ding{113} Prüfung auf fehlerhafte Personenentitäten (z.B. „des“, „Vereinsführer“)\\




\noindent\hrulefill

\section{LLM-Anreicherung und Metadaten-Extraktion \small 12.04.2025}
\small\textit{Integration von ChatGPT-API und Erweiterung der Metadaten-Extraktion}\\
\subsection*{Kurzbeschreibung}

Heute wurden die LLM-Anreicherungsskripte optimiert und die Metadatenextraktion aus JSON-Dateien weiterentwickelt. Die Skripte ermöglichen jetzt eine präzisere Erkennung von Entitäten und eine strukturierte Anreicherung der Transkribus-Daten mit zusätzlichen Metadaten durch den Einsatz von Large Language Models.

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Optimierung von ChatGPT-API-picture-to-JSON\_2024.py}
\ding{51} Code-Kommentare für bessere Dokumentation ergänzt\\
\ding{51} API-Kostenkalkulation präzisiert\\
\ding{51} Prompt-Engineering für die Analyse historischer Dokumente verbessert\\
\textbf{Ergebnis}: Zuverlässigere Extraktion von Metadaten aus Bildmaterial mit detaillierter Kostenkontrolle

\subsubsection*{\small Weiterentwicklung der CSV-Merger-Skripte}
\ding{51} Metadaten\_CSV\_Merger\_V2.py mit erweiterter Normalisierungsfunktion implementiert\\
\ding{51} Verbesserte Zusammenführung mehrerer CSV-Quellen\\
\ding{51} Robustere Fehlerbehandlung bei der CSV-Verarbeitung hinzugefügt\\
\textbf{Ergebnis}: Umfassendere Gesamtübersicht über alle Akten mit konsistenter Nummerierung

\subsection*{Nächste Schritte}
\ding{113} Automatisierte Validierung der extrahierten Metadaten implementieren\\
\ding{113} Named Entity Recognition für Militäreinheiten und Dienstgrade integrieren\\
\ding{113} Dashboard zur Visualisierung der Metadaten-Qualität entwickeln

\subsection*{Offene Fragen}
\ding{113} Wie kann die Qualität der LLM-Extraktion objektiv bewertet werden?\\
\ding{113} Skalierungsmöglichkeiten für größere Dokumentenmengen?

\section{Integration mit Transkribus XML Export \small 11.04.2025}
\small\textit{Erweiterung der Datenpipeline zur Anreicherung von Transkribus-XML-Dateien}\\
\subsection*{Kurzbeschreibung}

Das neue Modul \texttt{Transkribus\_XML\_Data\_Enricher\_with\_CSV.py} wurde entwickelt, um XML-Dateien aus Transkribus mit strukturierten Metadaten aus CSV-Dateien anzureichern. Dieses Skript ermöglicht die Zusammenführung von manuell erstellten Metadaten und automatisch extrahierten Informationen, um vollständigere Dokumentbeschreibungen zu erstellen.

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Entwicklung des XML-Enricher-Skripts}
\ding{51} XML-Parser für Transkribus-Dateien implementiert\\
\ding{51} Matching-Algorithmus zwischen XML- und CSV-Daten entwickelt\\
\ding{51} Automatische Anreicherung der XML-Dateien mit CSV-Metadaten\\
\textbf{Ergebnis}: Funktionierendes Skript zur Anreicherung von XML-Dateien mit zusätzlichen Metadaten

\subsubsection*{\small Integration des Finder-Tag-Systems}
\ding{51} \texttt{Image\_Tags\_to\_list.py} zur Extraktion von macOS Finder-Tags erstellt\\
\ding{51} Automatische Konvertierung von Finder-Tags in strukturierte CSV-Daten\\
\ding{51} Bereinigung und Normalisierung der extrahierten Tag-Informationen\\
\textbf{Ergebnis}: Erfolgreiche Integration des visuellen Tagging-Systems in die Metadatenpipeline

\subsection*{Technische Details zur XML-Anreicherung}
\begin{minted}{python}
# XML-Namespace festlegen (wie in den Transkribus-Dateien)
NS = {"ns": "http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15"}

# CSV einlesen und für Matching vorbereiten
df_csv = pd.read_csv(csv_file_path, sep=";", dtype=str, on_bad_lines='skip')
df_csv = df_csv[df_csv["Akte_Scan"].str.contains("Akte", na=False)]

# Extraktion der Seitenzahl für eindeutiges Matching
df_csv["csv_page_number"] = df_csv["Akte_Scan"].apply(
    lambda x: re.search(r"_S(\d+)", x).group(1) if re.search(r"_S(\d+)", x) else None
)

# XML-Dateien mit CSV-Informationen anreichern
for xml_file in xml_files:
    tree = ET.parse(xml_path)
    root = tree.getroot()
    
    # Metadaten aus Transkribus extrahieren
    transkribus_meta = root.find(".//ns:TranskribusMetadata", NS)
    doc_id = transkribus_meta.get("docId", "").strip()
    page_id = transkribus_meta.get("pageId", "").strip()
    
    # Matching mit CSV-Daten
    csv_match = find_matching_csv_entry(doc_id, xml_page_number)
    
    # CSV-Daten in XML integrieren
    csv_elem = ET.Element("CSVData")
    if csv_match:
        for key, value in csv_match.items():
            child = ET.SubElement(csv_elem, key)
            child.text = value
    
    # Angereicherte XML speichern
    root.append(csv_elem)
    tree.write(output_path, encoding="utf-8", xml_declaration=True)
\end{minted}

\subsection*{Nächste Schritte}
\ding{113} Integration der XML-Anreicherung in die bestehende Metadatenextraktion\\
\ding{113} Entwicklung eines Validierungssystems für die angereicherten XML-Dateien\\
\ding{113} Ausweitung der Extraktionsmöglichkeiten auf weitere Metadatenfelder

\noindent\hrulefill

\section{Integration von person\_matcher.py mit transkribus\_to\_base\_schema.py \small 09.04.2025}
\small\textit{Verbesserung der Personenerkennung durch Nutzung einer gemeinsamen CSV-Referenz}\\
\subsection*{Kurzbeschreibung}

Die beiden Module person\_matcher.py und transkribus\_to\_base\_schema.py wurden überarbeitet, um eine konsistente Personenerkennung zu gewährleisten. Die zentrale Verbesserung ist die Nutzung der CSV-Datei mit Personenmetadaten als gemeinsame Ground Truth. Dies ermöglicht eine zuverlässigere Erkennung und Matching von Personennamen mit Variationen in der Schreibweise.

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Integration von person\_matcher.py}
\ding{51} person\_matcher.py mit Funktionen für CSV-Einlesen und Fuzzy-Matching erweitert\\
\ding{51} Schnittstelle für den Zugriff auf bekannte Personen standardisiert\\
\ding{51} match\_person-Funktion für die Suche in der CSV-Datei optimiert\\
\textbf{Ergebnis}: Vereinheitlichter Personenabgleich über beide Module hinweg

\subsubsection*{\small Überarbeitung von transkribus\_to\_base\_schema.py}
\ding{51} Funktionen aus person\_matcher.py integriert\\
\ding{51} Gemeinsamen CSV-Pfad für Personenreferenzen eingerichtet\\
\ding{51} Personenerkennungslogik verbessert, um Fuzzy-Matching zu nutzen\\
\textbf{Ergebnis}: Zuverlässigere Erkennung von Personennamen mit konsistenter Referenzierung

\section{Objektorientierte Umstrukturierung der Datenextraktions-Pipeline \small 08.04.2025}
\small\textit{Verbesserung des Skripts auf Basis der Empfehlungen von Claude Code}\\
\subsection*{Kurzbeschreibung}

Die bestehende Datenextraktionspipeline wurde grundlegend überarbeitet und auf eine objektorientierte Struktur umgestellt. Statt der bisherigen Dictionary-basierten Implementierung nutzen wir nun die in `document\_schemas.py` definierten Klassen wie `BaseDocument`, `Person`, `Organization` und `Place`. Diese Umstellung bringt erhebliche Vorteile bei der Datenvalidierung und -konsistenz mit sich.

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Objektorientierte Umstrukturierung von transkribus\_to\_base\_schema.py}
\ding{51} Umstellung der Datenstrukturen auf Klassen statt Dictionaries.\\
\ding{51} Integration der Validierungsfunktionen mit Fehlerausgabe.\\
\ding{51} Anpassung der JSON-Serialisierung mittels to\_json()-Methode.\\
\textbf{Ergebnis}: Robusteres Skript mit automatischer Datenvalidierung und besserer Wartbarkeit.

\subsection*{Details zur Umstrukturierung}

\begin{minted}{python}
# Alter Ansatz:
result = create_base_schema(metadata_info, transcript_text)

# Neuer objektorientierter Ansatz:
from document_schemas import BaseDocument, Person, Place, Event, Organization

doc = BaseDocument(
    attributes=metadata_info,
    content_transcription=transcript_text,
    mentioned_persons=[Person(**p) for p in custom_data["persons"]],
    mentioned_organizations=[Organization(**o) for o in custom_data["organizations"]],
    mentioned_places=[Place(**pl) for pl in custom_data["places"]],
    mentioned_dates=custom_data["dates"]
)

# Mit Validierung
if not doc.is_valid():
    print(f"Fehler in Dokument: {doc.validate()}")
\end{minted}

\subsection*{Vorteile der neuen Implementierung}
\begin{itemize}
    \item \textbf{Datenvalidierung:} Automatische Überprüfung auf strukturelle Korrektheit
    \item \textbf{Typsicherheit:} Verbesserte Erkennung von Fehlern bereits zur Programmierzeit
    \item \textbf{Objektorientierung:} Zusammengehörige Daten und Funktionen in einer Klasse
    \item \textbf{Bessere Wartbarkeit:} Klare Schnittstellen und Kapselung von Implementierungsdetails
    \item \textbf{Erweiterbarkeit:} Einfachere Anpassung an neue Anforderungen durch Vererbung
\end{itemize}

\subsection*{Technische Details zur Integration}

\begin{minted}{python}
# In person_matcher.py: CSV-Einlese-Funktion
def load_known_persons_from_csv(csv_path: str) -> List[Dict[str, str]]:
    """
    Lädt die bekannten Personen aus der CSV-Datei.
    """
    if not os.path.exists(csv_path):
        print(f"Warnung: CSV-Datei nicht gefunden: {csv_path}")
        return []
    
    try:
        df = pd.read_csv(csv_path, sep=";")
        persons = []
        
        # Extrahiere relevante Spalten
        for _, row in df.iterrows():
            forename = row.get("schema:givenName", "").strip()
            familyname = row.get("schema:familyName", "").strip()
            
            if forename or familyname:  # Mindestens ein Namensteil vorhanden
                person = {
                    "forename": forename,
                    "familyname": familyname,
                    "id": row.get("Lfd. No.", ""),
                    # Weitere Metadaten
                }
                persons.append(person)
        
        return persons
    except Exception as e:
        print(f"Fehler beim Laden der CSV-Datei: {e}")
        return []

# Verbesserte person_matcher Funktion mit CSV-Standardwert
def match_person(
    person: Dict[str, str], 
    candidates: List[Dict[str, str]] = None, 
    threshold: int = 70
) -> Tuple[Optional[Dict[str, str]], int]:
    """
    Match a person against known persons from CSV (if no candidates provided)
    """
    if not person:
        return None, 0
        
    # Wenn keine Kandidaten angegeben, nutze CSV-Daten
    if candidates is None:
        candidates = KNOWN_PERSONS
\end{minted}

\subsection*{Nächste Schritte}
\ding{113} Testen der verbesserten Personenerkennung mit einem größeren Datensatz\\
\ding{113} Entwicklung von Methoden zur automatischen Zusammenführung von Personenduplikaten\\
\ding{113} Integration fortgeschrittener NER-Methoden für noch bessere Personenerkennung\\
\ding{113} Überprüfung aller generierten JSON-Dateien auf Validität

\subsection*{Offene Fragen}
\ding{113} Wie lässt sich die Konsistenz zwischen der CSV-Datei und extrahierten Personen automatisch überprüfen?\\
\ding{113} Sollen Schwellwerte für das Fuzzy-Matching je nach Dokumenttyp angepasst werden?

\section{Implementierung der Datenextraktions-Pipeline \small 03.04.2025}
\small\textit{{Diese Implementierung wurde mit Unterstützung von Claude Code und Sorin von RISE durchgeführt. Erster Einsatz von Claude Code}}\\
\subsection*{Kurzbeschreibung}

Implementierung der Datenkonvertierungspipeline vom Transkribus XML-Format in das projektspezifische JSON-Basisschema. Es wurden zwei Python-Module entwickelt: ein Schema-Modul und ein Konvertierungsmodul, die zusammen die Grundlage für die strukturierte Datenhaltung bilden.

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Definition des Basis-Schemas}
\ding{51} Erstellung des \textbf{\textit{document\_schemas.py}} Moduls mit Klassen für verschiedene Dokumenttypen.\\
\textbf{Ergebnis}: Implementierung der Basisklassen \texttt{Person}, \texttt{Organization}, \texttt{Place}, \texttt{Event} und \texttt{BaseDocument} sowie spezialisierte Klassen für \texttt{Brief}, \texttt{Postkarte} und \texttt{Protokoll} mit Validierungsfunktionen.

\subsubsection*{\small Konvertierungs-Pipeline}
\ding{51} Implementierung des \textbf{\textit{transkribus\_to\_base\_schema.py}} Skripts für die XML-Verarbeitung.\\
\textbf{Ergebnis}: Vollständige Pipeline für die Extraktion von Metadaten und Text aus Transkribus XML-Dateien sowie Konvertierung in das JSON-Basisschema mit automatischer Erkennung von benannten Entitäten (Personen, Organisationen, Orte, Daten).

\subsection*{Nächste Schritte}
\ding{113} Integration der Tag-Regeln aus der Transkribus-Anleitung in die Konvertierungspipeline. \\
\ding{113} Erweitern der automatischen Metadatenextraktion für komplexere Inhaltsanalysen.\\
\ding{113} Ausführen der Pipeline auf dem vollständigen Datensatz und Prüfung der Ergebnisse.\\

\subsection*{Offene Fragen}
\ding{113} Sollen zusätzliche spezialisierte Dokumenttypen implementiert werden?\\
\ding{113} Wie können Entitätsreferenzen zwischen verschiedenen Dokumenten hergestellt werden?

\textit{Diese Implementierung wurde mit Unterstützung von Claude Code und Sorin von RISE durchgeführt.}

\noindent\hrulefill
\section{Festlegung Tagging Regeln \small 11.03.2025 } % Kurztitel

\subsection*{Kurzbeschreibung}
Hier werden die Tagging Regeln in Transkribus beschrieben
 
\section*{Personen \texttt{\texttt{\textbf{{\colorbox{person}{person}}}}}}

Mit dem Tag \texttt{\texttt{\texttt{\textbf{{\colorbox{person}{person}}}}}} sollen alle strings getaggt werden, die eine direkte Zuordnung eier Person ermöglichen. \\

\noindent\ding{43} Beispiel 1: Vereinsführer, Alfons, Zimmermann, Alfons Zimmermann, Z. A.Zimmermann, Herr Zimmermann, Herr Alfons Zimmermann, etc \\
\ding{43} Beispiel 2: Gauleitung, Gauleiter, Gauleiter Max Mustermann, Gauleiter M., Gauleiter Mustermann, etc\\
\ding{43} Beispiel 3: Oberlehrer, Chorleiter, etc, wenn Ort, Name oder Organisation bekannt. \\

\section*{Signaturen \texttt{\texttt{\textbf{{\colorbox{signature}{signature}}}}}}

Mit dem Tag \texttt{\texttt{\texttt{\textbf{{\colorbox{signature}{signature}}}}}} sollen alle Strings getaggt werden, die eine handschriftliche Unterschrift darstellen. Dieses Tag dient dazu, Unterschriften von klar erkennbaren Personennamen im Fließtext zu unterscheiden. \\

\noindent\ding{43} Beispiel 1: **Eindeutig lesbare Signaturen** werden direkt getaggt:  
\texttt{\textbf{\textless signature\textgreater R. Weiss\textless /signature\textgreater}}.\\  

\ding{43} Beispiel 2: **Teilweise unleserliche Signaturen** werden mit dem Tag \texttt{unclear} innerhalb von \texttt{signature} markiert:  
\texttt{\textbf{\textless signature\textgreater R. We\textless unclear\textgreater [...]\textless /unclear\textgreater\textless /signature\textgreater}}.\\  

\ding{43} Beispiel 3: **Wenn nur ein Teil des Namens lesbar ist, aber eine Identifikation unsicher bleibt**, sollte die Unterschrift vollständig im Tag \texttt{unclear} innerhalb von \texttt{signature} stehen:  
\texttt{\textbf{\textless signature\textgreater \textless unclear\textgreater Unleserlich\textless /unclear\textgreater \textless /signature\textgreater}}.\\  

\ding{43} Beispiel 4: **Wenn eine Signatur einer bekannten Person zugeordnet werden kann, aber nicht vollständig lesbar ist, bleibt die Signatur erhalten und wird nicht als „Person" getaggt**:  
\texttt{\textbf{\textless signature\textgreater A. Zimm\textless unclear\textgreater [...]\textless /unclear\textgreater\textless /signature\textgreater}}.\\  

\section*{Organisationen \texttt{\texttt{\textbf{{\colorbox{organization}{organization}}}}}}


Mit dem Tag \texttt{\texttt{\textbf{{\colorbox{organization}{organization}}}}} sollen alle Strings getaggt werden, die eine direkte Zuordnung einer Organisation ermöglichen. \\

\noindent\ding{43} Beispiel 1: Männerchor Murg, Verein Deutscher Arbeiter (V.D.A.), Murgtalschule, etc.\\
\ding{43} Beispiel 2: Abkürzungen, wenn sie eine Organisation eindeutig bezeichnen, z.B. V.D.A., NSDAP, STAGMA, etc.\\
\ding{43} Beispiel 3: Wenn der Organisationsname mit einer Positionsangabe kombiniert ist, wird nur der Organisationsname getaggt: „\textless person\textgreater Vereinsleiter \textless person\textgreater des \textbf{\textless organisation\textgreater Männerchor Murg\textless /organisation\textgreater}". \\

\section*{Orte \texttt{\texttt{\textbf{{\colorbox{place}{place}}}}}}


Mit dem Tag\texttt{\texttt{\textbf{{\colorbox{place}{place}}}}} sollen alle Strings getaggt werden, die sich auf einen geografischen Ort beziehen. \\
\indent\textit{Hintergund ist Fehlervermeidung: Manche Organisationen haben mehrere Standorte (z. B. "Badischer Sängergau" kann in Karlsruhe oder Mannheim sein). Ein explizites Tagging vermeidet Verwechslungen.
Flexibilität: Falls sich eine Organisation an mehreren Orten befindet oder in einem bestimmten Kontext mit einem anderen Ort assoziiert wird, bleibt die Information strukturiert erhalten.} \\

\noindent\ding{43} Beispiel 1: Murg (Baden), Freiburg, Berlin, Murgtal, Schwarzwald, etc.\\
\ding{43} Beispiel 2: Orte mit näherer Bestimmung, z.B. „bei Berlin", „im Murgtal", "Mayerhof Nebenzimmer" werden getaggt, und die nähere Bestimmung muss innerhalb des Tags. Beispiel: „ \textbf{\textless place\textgreater  im Murgtal\textless /place\textgreater }".\\
\ding{43} Beispiel 3: Adressen oder Ortsangaben in Verbindung mit Organisationen, z.B. „\textless organisation\textgreater Universität \textbf{\textless place\textgreater  Basel\textless /place\textgreater} \textless /organisation\textgreater" oder „Postfach 6, \textbf{\textless place\textgreater  Murg \textless /place\textgreater }". \\

\section*{Datum \texttt{\texttt{\textbf{{\colorbox{date}{date}}}}}}


Mit dem Tag \texttt{\texttt{\texttt{\textbf{{\colorbox{date}{date}}}}}} werden alle expliziten Datumsangaben markiert und bereits im Tag um das format dd.mm.yyyy ergänzt.\\

\noindent\ding{43} Beispiel 1: 9. Oktober 1940, 20.10.1940, den 3. Mai 1938, etc.\\
\ding{43} Beispiel 2: Relative Datumsangaben („gestern", „letzten Freitag") werden getaggt.\\
\ding{43} Beispiel 3: Falls ein Datum in Kombination mit einem Ort steht, wird nur das Datum getaggt: „\textbf{\textless place\textgreater Murg (Baden)\textless /place\textgreater }, den \textbf{\textless date\textgreater 9. Oktober 1940\textless /date\textgreater }". \\

\section*{Abkürzungen \texttt{\textbf{{\colorbox{abbrev}{abbrev}}}}}


Mit dem Tag \texttt{\texttt{\textbf{{\colorbox{abbrev}{abbrev}}}}} werden alle Abkürzungen getaggt, die für eine eindeutige Entität stehen. \\

\noindent\ding{43} Beispiel 1: Dr., Prof., St., Hr., Frl., Dipl.-Ing., etc.\\
\ding{43} Beispiel 2: Organisationskürzel, wenn sie eindeutig sind: „\textbf{\textless abbrev\textgreater V.D.A.\textless /abbrev\textgreater }".\\
\ding{43} Beispiel 3: Falls eine ausgeschriebene Variante im selben Dokument vorhanden ist, bleibt die Abkürzung getaggt: \textbf{\textless person\textgreater \textless abbrev\textgreater Dr.\textless /abbrev\textgreater Weiß\textless /person\textgreater}


\section*{Unclear\texttt{\textbf{{\colorbox{unclear}{unclear}}}}}


Mit dem Tag \texttt{\texttt{\textbf{{\colorbox{unclear}{unclear}}}}} werden unleserliche oder schwer entzifferbare Textstellen markiert. \\

\noindent\ding{43} Beispiel 1: Unklare Zeichen oder fehlende Buchstaben: „Er wohnte in \textbf{\textless unclear\textgreater [...]\textless unclear\textgreater }".\\
\ding{43} Beispiel 2: Teilweise lesbare Wörter: „\textbf{\textless place\textgreater Frei\textless unclear\textgreater [...]\textless unclear\textgreater \textless place\textgreater }".\\


\section*{Sic \texttt{\textbf{{\colorbox{sic}{sic}}}}}


Mit dem Tag \texttt{\texttt{\textbf{{\colorbox{sic}{sic}}}}} werden Wörter markiert, die absichtlich in einer falschen oder ungewöhnlichen Schreibweise beibehalten werden. \\

\noindent\ding{43} Beispiel 1: Offensichtliche Tippfehler, wenn sie im Originaltext so vorkommen: „Er hatt \textbf{\textless sic\textgreater einen\textless /sic\textgreater } große Freude."\\
\ding{43} Beispiel 2: Veraltete oder falsche Schreibweisen: „\textbf{\textless sic\textgreater Feber\textless /sic\textgreater }" für Februar.\\
\ding{43} Beispiel 3: Falls eine Korrektur notwendig ist, kann sie als Kommentar ergänzt werden. \\


%___________________________________________________________________________
\newpage % Nach dem Inhaltsverzeichnis eine neue Seite


\section{Überblick Hilfscript\\ChatGPT\_Api\_TranskribusXML\_to\_JSONv3.py \\\small 06.03.2025}
Dieses Skript verarbeitet XML-Dateien aus einer definierten Ordnerstruktur und sendet deren Inhalt an die OpenAI-API zur automatischen Analyse und Extraktion relevanter Metadaten. Das generierte Ergebnis wird als JSON-Datei gespeichert.

Das Skript ist speziell auf historische Dokumente (z. B. aus dem Männerchor Murg Corpus, 1925-1945) zugeschnitten. Es analysiert und strukturiert die Daten, um relevante Informationen wie Autoren, Empfänger, Orte, Ereignisse und Zeitangaben zu extrahieren.

\section{Voraussetzungen \& Einrichtung}

\subsection{API Key setzen}
Bevor das Skript ausgeführt wird, muss der OpenAI-API-Schlüssel als Umgebungsvariable gesetzt werden. Dies kann dauerhaft in der ~/.zshrc-Datei erfolgen:

\begin{minted}{bash}
    export OPENAI\_API\_KEY=''sk-...''
    source ~/.zshrc
\end{minted}    

Alternativ kann das Skript mit VS Code gestartet werden, indem es aus dem Terminal mit folgendem Befehl aufgerufen wird:

\begin{minted}{bash}
code .
\end{minted}

\subsection{Python-Bibliotheken installieren}
Folgende Bibliotheken werden benötigt:

\begin{minted}{bash}
pip install openai
\end{minted}

folgende Module werden gebraucht:

\begin{minted}{bash}
    import json
    import os
    import xml.etree.ElementTree as ET
    import openai
    import re
    import time
\end{minted}

\section{Funktionsweise}

Das Skript ist in folgende Hauptbestandteile gegliedert:

\subsection{Basis-Einstellungen}
\begin{itemize}
\item Zähler zur Erfassung der verarbeiteten Dateien und Token-Kosten.
\item API-Schlüssel wird aus der Umgebungsvariable geladen.
\item Pfad-Definitionen für Input- und Output-Verzeichnisse.
\end{itemize}

\subsection{Verzeichnisstruktur durchlaufen}
Das Skript iteriert über alle 7-stelligen Ordner im Basisverzeichnis (base\_input\_directory). In diesen Ordnern sucht es nach Unterordnern mit Namen Akte\_xxx\_pdf oder Akte\_xxx, die wiederum einen page-Ordner enthalten.

Falls kein page-Ordner gefunden wird, wird die Verarbeitung dieser Akte übersprungen.

\subsection{Verarbeitung der XML-Dateien}
Jede XML-Datei im page-Ordner wird eingelesen und analysiert:
\begin{itemize}
\item Seitennummer extrahieren: Die Dateinamen haben das Muster p001.xml, p002.xml usw.
\item XML-Daten einlesen: Nutzung von xml.etree.ElementTree zur Extraktion von TranskribusMetadata und TextEquiv-Daten.
\item Fehlermanagement: Falls eine Datei nicht geparst werden kann oder keinen verwertbaren Text enthält, wird sie übersprungen.
\end{itemize}

\subsection{Strukturierung der Daten in JSON}
Die extrahierten Informationen werden in einem JSON-Format gespeichert. Dazu gehören:
\begin{itemize}
\item Metadaten (Dokument-ID, Seiten-ID, Bild- und XML-URL)
\item Autor und Empfänger mit Name, Rolle und zugehöriger Organisation
\item Erwähnte Personen, Organisationen, Ereignisse und Orte
\item Dokumentart (z. B. Brief, Protokoll, Rechnung)
\item Dokumentformat (z. B. Handschrift, maschinell, mit Unterschrift, Bild)
\end{itemize}

\subsection{API-Anfrage an OpenAI}
Ein Prompt wird erstellt, um die Inhalte durch die OpenAI-API analysieren zu lassen. Dabei wird explizit vorgegeben:
\begin{itemize}
\item Die historische Relevanz der Dokumente (1925-1945).
\item Die Aufgabenstellung (Identifikation von Dokumenttypen, Metadaten und Inhalten).
\item Die genaue Formatierung der JSON-Antwort.
\end{itemize}

\section{Fehlerbehandlung}
Das Skript enthält mehrere Mechanismen zur Fehlerbehandlung:
\begin{itemize}
\item Fehlermeldungen beim XML-Einlesen (try-except beim Parsen)
\item Fehlermeldungen bei API-Anfragen (try-except um den OpenAI-Aufruf)
\item Fehlermeldungen bei JSON-Speicherung (try-except beim Schreiben der Datei)
\item Logging von Problemen (print(f''Fehler beim Parsen der API-Antwort: {e} ''))
\end{itemize}

Falls Fehler auftreten, werden sie ausgegeben und das Skript setzt die Verarbeitung der nächsten Datei fort, anstatt komplett abzubrechen.

\section{Fazit}
Dieses Skript automatisiert die Verarbeitung von XML-Dokumenten, extrahiert deren Inhalte und strukturiert die Daten in JSON-Format, das von OpenAI-API analysiert wird. Die Ergebnisse werden gespeichert und abschließend statistisch ausgewertet. Durch Fehlerbehandlung und Logging wird sichergestellt, dass auch bei Problemen das Skript robust bleibt. Dokumentation geschrieben mit ChatGPT.

%___________________________________________________________________________
\noindent\hrulefill
\section{Tagging der JPGEGs im AppleFinder \small 26.10.24 } % Kurztitel

\subsection*{Kurzbeschreibung}

Überlegung:
JPEGs sollen bereits im Apple Finder mit Tags versehen werden, um eine effiziente, automatisierte Transkription der Chorunterlagen des Männerchors Murg zu ermöglichen. Geplant ist die Kombination von ChatGPT und Transkribus zur Erkennung unterschiedlicher Dokumententypen. Ein Tag-System, bestehend aus \textbf{„Maschinell"} für maschinengeschriebene und \textbf{„Handschrift"} für handschriftliche Dokumente, gewährleistet die gezielte Zuordnung zur jeweils geeigneten OCR-Software \textit{(Maschinenschrift mit ChatGPT, Handschrift mit Transkribus ''German Giant'')}.

Dokumente, die sowohl maschinell erstellten Text als auch handschriftliche Elemente enthalten, werden entsprechend ihrer Hauptinformationsgehalt getaggt. Zusätzlich erhalten alle Dokumente mit Unterschriften den Tag \textbf{„Unterschrift"}, um eine gezielte Verarbeitung dieser Elemente sicherzustellen.

\subsection{AppleFinder Tags}

\textcolor{yellow}{\Large $\bullet$} \textbf{Handschrift} \\
\textcolor{blue}{\Large $\bullet$} \textbf{Maschinell} \\
\textcolor{gray}{\Large $\bullet$} \textbf{mitUnterschrift} \\
\textcolor{purple}{\Large $\bullet$} \textbf{Bild} \\

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small Handschriften tagging}
\ding{51} taggen \textcolor{yellow}{\Large $\bullet$} \textbf{Handschrift} in AppleFinder. \\
\ding{51} taggen \textcolor{blue}{\Large $\bullet$} \textbf{Maschinell} in AppleFinder. \\
\ding{51} taggen \textcolor{purple}{\Large $\bullet$} \textbf{Bild} \\
\ding{51} taggen \textcolor{gray}{\Large $\bullet$} \textbf{mitUnterschrift} \\
\\
\textbf{Ergebnis}: Handschriften, Maschinell, Bilder und alle handschriftlichen Unterschriften getaggt

\subsection*{Nächste Schritte}
\ding{113} Skripte schreiben, um maschinelle Text zu extrahieren 
\ding{113} Transkribus für Handschriftliches anschmeißen. \\
\ding{113} Nach Gemeinsamkeiten in den Texten suchen, um automatisierte Abfrage für ChatGPT zu erstellen. \\ 
\ding{113} Ggf. Aufteilung in unterschiedliche Korpora (Briefe handschr. Briefe schreibmaschine, Zeitungsunterlagen.)\\
\ding{113} Transkribus für Handschriften verwenden. \\

\subsection*{Offene Fragen}
\ding{113} Sollen die Bilder gelöscht werden?\\
%-------------------------------------------------------


%___________________________________________________________________________

\noindent\hrulefill
\section{JPG Datenbereinigung - leere Seiten löschen \small 25.10.2024 } % Kurztitel

\subsection*{JPG Datenbereinigung}
Alle JPGs ohne Inhalt, also beispielsweise Rückseiten, werden gelöscht. Regel: sobald etwas handschriftlich oder gedruckt auf einer Seite steht, bleibt es erhalten. Im Moment sind auch Bilder (Bsp. Postkarten inbegriffen.Bilder mit Taggs 
\subsection{Anmerkung}
Geschichte/Chronik/Gründung des Männerchors in Akte 323

\subsection*{Erledigte Aufgaben}
\subsubsection*{\small JPG Datenbereinigung }
\ding{51}Alle JPGs ohne Inhalt, also beispielsweise Rückseiten, werden gelöscht.\\
\textbf{Ergebnis}: Reiner JPG Korpus mit Schriftgut, aber auch Bildern (bspw. Postkarten)

\subsection*{Nächste Schritte}
\ding{113} Nach Gemeinsamkeiten in den Texten suchen, um automatisierte Abfrage für ChatGPT zu erstellen. \\ 
\ding{113}Ggf. Aufteilung in unterschiedliche Korpora (Briefe handschr. Briefe schreibmaschine, Zeitungsunterlagen.)\\
\ding{113} Transkribus für Handschriften verwenden.

\subsection*{Offene Fragen}
\ding{113} Sollen die Bilder gelöscht werden?\\
\ding{113} Handschriftliche, maschinengeschriebene und gemischte Daten taggen? Ggf. erst später mit ChatGPT.\\
\ding{113} Transkribus für Handschriften verwenden?

%___________________________________________________________________________

\noindent\hrulefill

\section{Datennormalisierung PDF zu JPEG \small 24.10.2024}
\subsection*{Kurzbeschrieb}
Heute zwei Python-Skripte zur Normalisierung der Akten geschrieben:

\subsection*{Erledigte Augaben}
\subsubsection*{\small PDF zu JPG Konvertierung}
\ding{51} Skript \textbf{\textit{JPEG-to-PDF.py}} geschrieben.  \\
\textbf{Ergebnis} Alle PDF-Seiten in JPGs umgewandelt, Dateinamen mit Seitenzahlen formatiert.

\subsubsection*{\small Prüfung der Aktennummern}
\ding{51} Skript \textbf{\textit{Check-if-all-files-complete.py}} geschrieben. \\
\textbf{Ergebnis}: Überprüft, ob Akten von 001 bis 425 vorhanden sind. Alle Akten sind vollständig in JPG umgewandelt.

\subsection*{Nächste Schritte}
\ding{113} Daten für OCR-Bereinigung vorbereiten, leere Seiten manuell entfernen.
\subsection*{Offene Fragen}
\ding{113} Handschriftliche, maschinengeschriebene und gemischte Daten taggen? Ggf. erst später mit ChatGPT.

\noindent\hrulefill

%___________________________________________________________________________
\end{document}